# -*- coding: utf-8 -*-
"""Final_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uNbK6qz8xnZJv39TYfRkINmKlv56m6-e
"""

import librosa
import soundfile
import os, glob, pickle
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import accuracy_score

#Extract features (mfcc, chroma, mel) from a sound file
def extract_feature(file_name, mfcc, chroma,mel):
  with soundfile.SoundFile(file_name) as sound_file:
    X = sound_file.read(dtype="float32")
    sample_rate=sound_file.samplerate # the higher the sample rate and the better the quality.
    if chroma:
      stft=np.abs(librosa.stft(X))  #The STFT represents a signal in the time-frequency domain by computing discrete Fourier transforms (DFT) over short overlapping windows.
      result=np.array([])
    if mfcc:
      mfccs=np.mean(librosa.feature.mfcc(y=X, sr=sample_rate,n_mfcc=40).T, axis=0)
      result=np.hstack((result, mfccs))
    if chroma:
      hop_length=512
      chroma=np.mean(librosa.feature.chroma_stft(S=stft,sr=sample_rate,hop_length=hop_length).T,axis=0)
      result=np.hstack((result, chroma))
    if mel:
        mel=np.mean(librosa.feature.melspectrogram(y=X,sr=sample_rate).T,axis=0)
        result=np.hstack((result, mel))
  return result

#Emotions in the dataset
emotions={'01':'neutral','02':'calm','03':'happy','04':'sad','05':'angry',
'06':'fearful','07':'disgust','08':'surprised'}
print("Emotions in the data set are : " , emotions)
#Emotions to observe
observed_emotions=['angry', 'happy', 'neutral', 'sad']
print("Emotions being observed are : " , observed_emotions)

from google.colab import drive
drive.mount('/content/drive')

#Load the data and extract features for each sound file
def load_data(test_size):
  x,y=[],[]
  for file in glob.glob("/content/drive/MyDrive/ML_LAB/archive/Actor_*/*.wav"):
    file_name=os.path.basename(file)
    emotion=emotions[file_name.split("-")[2]]
    if emotion not in observed_emotions:
      continue
    try:
      feature=extract_feature(file, mfcc=True, chroma=True,mel=True)
    except:
      continue
    x.append(feature)
    y.append(emotion)
  return train_test_split(np.array(x), y, test_size=test_size, random_state=0)

#Split the dataset
x_train,x_test,y_train,y_test=load_data(test_size=0.25)

y_train[:5]

#Get the shape of the training and testing datasets
print((x_train.shape[0], x_test.shape[0]))

#Get the number of features extracted
print(f'Features extracted: {x_train.shape[1]}')

from sklearn.svm import SVC # "Support vector classifier"
model = SVC(kernel='linear', random_state=0)

#Initialize the Multi Layer Perceptron Classifier
#model=MLPClassifier(alpha=0.01, batch_size=256, epsilon=1e-08,hidden_layer_sizes=(300,), learning_rate='adaptive', max_iter=500)

#Train the model
model.fit(x_train,y_train)

#Predict for the test set
y_pred=model.predict(x_test)

#Calculate the accuracy of our model
accuracy=accuracy_score(y_true=y_test, y_pred=y_pred)

#Print the accuracy
print("Accuracy: {:.2f}%".format(accuracy*100))

def load_data_file(file_name):
  x,y=[],[]
  emotion=emotions[file_name.split("-")[2]]
  if emotion not in observed_emotions:
    exit
  try:
    feature=extract_feature(file_name, mfcc=True, chroma=True,mel=True)
  except:
    exit
  x.append(feature)
  y.append(emotion)
  return x,y

a,b=load_data_file("/content/drive/MyDrive/ML_LAB/archive/Actor_07/03-02-04-01-01-01-07.wav")

a

b

model.predict(a)

print(f'Features extracted: {x_train.shape[1]}')

import pickle

filename='trained_model-2.sav'
pickle.dump(model,open('trained_model-2.sav','wb'))

loaded_model=pickle.load(open('trained_model-2.sav','rb'))

def load_data_file(file_name):
  x,y=[],[]
  emotion=emotions[file_name.split("-")[2]]
  if emotion not in observed_emotions:
    exit
  try:
    feature=extract_feature(file_name, mfcc=True, chroma=True,mel=True)
  except:
    exit
  x.append(feature)
  y.append(emotion)
  return x,y

c,d=load_data_file("/content/drive/MyDrive/ML_LAB/archive/Actor_07/03-02-05-01-01-01-07.wav")

res=loaded_model.predict(c)
res

d

